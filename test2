from bs4 import BeautifulSoup as BS

from selenium import webdriver
from selenium.webdriver.chrome.service import Service

import pandas as pd
import sys, time
from datetime import datetime

url = "https://finance.yahoo.com/quote/{0}/news?p={0}"
##tickers = ['FB','MSFT','AAPL','NVDA','AMD','XLNX','QCOM','MU']
tickers = ['INTC']
csv_format = "price_%s.csv"
exe = "/Users/sl/Downloads/chromedriver"
service = Service(exe)

def req_ticker(ticker, max_scroll=sys.maxsize):
    ticker_url = url.format(ticker)
    print("info> reading:", ticker_url)
    soup = BS(ticker_url,"html.parser")
    lis = soup.find_all("span")
    return [lis.getText()]

now = datetime.now().strftime('%Y-%m-%d %I:%M:%S %p')

for ticker in tickers:
    csv = csv_format % ticker
    headings = req_ticker(ticker, 8)
    data = list(zip(headings, [now] * len(headings)))
    tmp_df = pd.DataFrame(reversed(data), columns=[ticker,'time'])
    try:
        csv_df = pd.read_csv(csv)
        df = pd.concat([csv_df, tmp_df], ignore_index=True)
    except:
        df = tmp_df
    ##df = df.drop_duplicates(subset=[ticker], keep="first", ignore_index=True)
    df.to_csv(csv, index=False)
